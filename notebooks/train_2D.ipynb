{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a 2D model\n",
    "Define parameters here, imports and load the GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define path to config file\n",
    "config_path = r\"config_2D_test.yml\"\n",
    "# define GPU idx\n",
    "GPU_idx = \"0\"\n",
    "# define GPU max memory\n",
    "GPU_max_memory = 22000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tv4sbUfUXbVa",
    "outputId": "22b0628c-936e-4643-ac9a-d8bbb031c17e"
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "import csv\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = GPU_idx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow import keras\n",
    "from data_generator import data_generator_2D\n",
    "from UNet_RCAN_2D import UNet_RCAN\n",
    "from loss import custom_loss_with_l2_reg\n",
    "tf.random.set_seed(42)\n",
    "print(tf.__version__)\n",
    "!nvcc --version\n",
    "!cat /usr/local/cuda/version.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load GPUs\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.set_logical_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.LogicalDeviceConfiguration(memory_limit=GPU_max_memory)])\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading\n",
    "Data is loaded and preprocessed (patches cropped, normalized)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Config file is red, some data instances displayed, and the config file printed out to double check parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read config file\n",
    "with open(config_path, \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "data_config = config['data']\n",
    "model_config = config['model']\n",
    "callback = config['callbacks']\n",
    "x_train, y_train = data_generator_2D(data_config)\n",
    "\n",
    "# plot training data\n",
    "ix = np.random.randint(0,len(x_train),4)\n",
    "fig = plt.figure(figsize=(15,7))\n",
    "\n",
    "for i in range(4):\n",
    "    norm_x = np.linalg.norm(x_train[ix[i]], axis=(0, 1))\n",
    "    fig.add_subplot(2,4, 2*i+1)\n",
    "    cmap=plt.get_cmap('magma')\n",
    "    plt.imshow(x_train[ix[i],:,:,0].squeeze(),cmap)\n",
    "    plt.title('Low SNR',fontdict={'fontsize':18})\n",
    "    plt_axis = plt.axis('off')\n",
    "    \n",
    "    fig.add_subplot(2,4, 2*i+2)\n",
    "    cmap=plt.get_cmap('magma')\n",
    "    plt.imshow(y_train[ix[i],:,:,0].squeeze(),cmap)\n",
    "    plt.title('High SNR',fontdict={'fontsize':18})\n",
    "    plt_axis = plt.axis('off')\n",
    "\n",
    "# create model instance\n",
    "model_input = Input((data_config['patch_size'], data_config['patch_size'], 1))\n",
    "model = UNet_RCAN(model_config)\n",
    "\n",
    "if model_config['clip_value'] is not False or model_config['clip_value'] == 0:\n",
    "    # add gradient clipping\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=model_config['lr'], clipvalue=model_config['clip_value'])\n",
    "else:\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=model_config['lr'])\n",
    "    \n",
    "model.compile(optimizer=optimizer, loss=custom_loss_with_l2_reg(model, model_config['loss_type'], data_config['patch_size'], model_config['norm_factor'], model_config['edge_regularization'], model_config['l2_regularization']))\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=callback['patience_stop'], verbose=1),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=callback['factor_lr'], patience=callback['patience_lr']),\n",
    "    ModelCheckpoint(filepath=model_config['save_dr'], verbose=1, save_best_only=True, save_weights_only=True)]\n",
    "\n",
    "print(config)\n",
    "print(model_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(model_config['save_config'], exist_ok=True)\n",
    "\n",
    "results = model.fit(x=x_train, y=y_train, batch_size=model_config['batch_size'],\n",
    "                epochs=model_config[\"n_epochs\"],\n",
    "                verbose=1, callbacks=callbacks, validation_split=callback[\"val_split\"]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save results\n",
    "Model is saved as h5, the loss curve as csv and png and the config file is stored for documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save config file\n",
    "shutil.copyfile(config_path, model_config['save_config'] + \"/config.yml\")\n",
    "    \n",
    "# Save training history\n",
    "def save_loss_plot(training_history, save_dir, img_format=\"png\"):\n",
    "    fig = plt.figure()\n",
    "    x_ticks = range(1, len(training_history.history[\"loss\"])+1)\n",
    "    if callback[\"val_split\"] == 0:\n",
    "        plt.plot(x_ticks, training_history.history[\"loss\"], label=\"training\", color=\"#1f77b4\")\n",
    "        plt.plot(x_ticks, training_history.history[\"output_1_loss\"], \"--\", label=\"output_1_loss\", color=\"#1f77b4\")\n",
    "        plt.plot(x_ticks, training_history.history[\"output_2_loss\"], \"--\", label=\"output_2_loss\", color=\"#1f77b4\")\n",
    "    else: \n",
    "        plt.plot(x_ticks, training_history.history[\"loss\"], label=\"training\", color=\"#1f77b4\")\n",
    "        plt.plot(x_ticks, training_history.history[\"val_loss\"], label=\"validation\", color=\"#ff8010\")\n",
    "        plt.plot(x_ticks, training_history.history[\"output_1_loss\"], \"--\", label=\"train output_1_loss\", color=\"#1f77b4\")\n",
    "        plt.plot(x_ticks, training_history.history[\"output_2_loss\"], \"--\", label=\"train output_2_loss\", color=\"#1f77b4\")\n",
    "        plt.plot(x_ticks, training_history.history[\"val_output_1_loss\"], \"--\", label=\"val output_1_loss\", color=\"#ff8010\")\n",
    "        plt.plot(x_ticks, training_history.history[\"val_output_2_loss\"], \"--\", label=\"val output_2_loss\", color=\"#ff8010\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.savefig(save_dir + r\"/loss.\" + img_format)\n",
    "\n",
    "def save_loss_txt(training_history, save_dir):\n",
    "    with open(save_dir + r\"/loss.csv\", \"w\") as outfile:\n",
    "        writer = csv.writer(outfile)\n",
    "        writer.writerow(training_history.history.keys())\n",
    "        writer.writerows(zip(*training_history.history.values()))\n",
    "    \n",
    "save_loss_plot(results, model_config['save_config'], img_format=\"png\")\n",
    "save_loss_txt(results, model_config['save_config'])\n",
    "\n",
    "# save weights\n",
    "model.save_weights(model_config[\"save_dr\"])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Denoising_UNET_RCAN_3D.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
